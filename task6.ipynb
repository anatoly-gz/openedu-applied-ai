{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Анализ изображений и видео\n",
        "\n",
        "Теперь вам предстоит самостоятельно попробовать распознать людей на изображениях, с помощью моделей компьютерного зрения и библиотек машинного обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv8-l37o0LEA",
        "outputId": "4df8c60f-6549-4194-a482-7ea399993f80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'YOLOv3-TensorFlow-2.x' already exists and is not an empty directory.\n",
            "/content/YOLOv3-TensorFlow-2.x\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.9/dist-packages (from -r ./requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r ./requirements.txt (line 2)) (1.10.1)\n",
            "Collecting wget>=3.2\n",
            "  Using cached wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: seaborn>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from -r ./requirements.txt (line 4)) (0.12.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.3.1 (from versions: 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.3.1\u001b[0m\u001b[31m\n",
            "\u001b[0m--2023-04-21 15:35:13--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘model_data/yolov3.weights.1’\n",
            "\n",
            "yolov3.weights.1    100%[===================>] 236.52M  69.8MB/s    in 3.6s    \n",
            "\n",
            "2023-04-21 15:35:17 (66.1 MB/s) - ‘model_data/yolov3.weights.1’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!git clone https://github.com/anushkadhiman/YOLOv3-TensorFlow-2.x.git\n",
        "%cd YOLOv3-TensorFlow-2.x\n",
        "!pip install -r ./requirements.txt\n",
        "!wget -P model_data https://pjreddie.com/media/files/yolov3.weights"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Скачайте исходные данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "60K76ftm0LEC"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "\n",
        "DATA = ['https://de.ifmo.ru/--openedu/dataprocessing/appliedai/img/20.jpg',\n",
        "        'https://de.ifmo.ru/--openedu/dataprocessing/appliedai/img/24.jpg',\n",
        "        'https://de.ifmo.ru/--openedu/dataprocessing/appliedai/img/28.jpg',\n",
        "        'https://de.ifmo.ru/--openedu/dataprocessing/appliedai/img/23.jpg',\n",
        "        'https://de.ifmo.ru/--openedu/dataprocessing/appliedai/img/0.jpg',\n",
        "        'https://de.ifmo.ru/--openedu/dataprocessing/appliedai/img/26.jpg',\n",
        "        'https://de.ifmo.ru/--openedu/dataprocessing/appliedai/img/8.jpg',\n",
        "        'https://de.ifmo.ru/--openedu/dataprocessing/appliedai/img/34.jpg',\n",
        "        'https://de.ifmo.ru/--openedu/dataprocessing/appliedai/img/12.jpg',\n",
        "        'https://de.ifmo.ru/--openedu/dataprocessing/appliedai/img/31.jpg']\n",
        "SCORE_THRESHOLD = 0.5\n",
        "\n",
        "os.makedirs('data')\n",
        "images = [f'{i}.jpg' for i in range(1, len(DATA)+1)]\n",
        "for image, link in zip(images, DATA):\n",
        "  urlretrieve(link, f'data/{image}')\n",
        "os.makedirs('output')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Выполните распознавание"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRwiEJ53SxgZ",
        "outputId": "fb13b020-51d7-459c-bcbf-249190b0e902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ],
      "source": [
        "from yolov3.utils import Load_Yolo_model, detect_image\n",
        "from IPython.display import display, Image\n",
        "\n",
        "model = Load_Yolo_model()\n",
        "for image in images:\n",
        "  detect_image(model, f'data/{image}', f'output/{image}', score_threshold=SCORE_THRESHOLD)\n",
        "  display(Image(filename=f'output/{image}', width=600) )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Составьте матрицы ошибок и вычислите метрики\n",
        "   Правила заполнения:\n",
        "   - TP (True Positive) — объект классифицирован правильно (т.е. мнение классификатора и эксперта совпало);\n",
        "   - TN (True Negative) — так как объектов много (не только людей), считать этот параметр всегда равным 0;\n",
        "   - FP (False Positive) — классификатор говорит, что выделенный объект является человеком, эксперт говорит, что нет;\n",
        "   - FN (False Negative) — эксперт видит человека, классификатор - нет.\n",
        "\n",
        "   *Пример:* На фотографии 4 человека. Классификатор нашел троих, тогда TP=3, FN=1, FP=0, TN=0\n",
        "   \n",
        "   *Пример:* На фотографии 4 человека. Классификатор говорит, что людей 6 (принял куст и светофор за двух людей). Тогда TP=4, FP=2, FN=0, TN=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PrXeshOWX4o",
        "outputId": "24690aae-3591-417c-f34b-9f45a31bd6be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "true_positive=42 false_negative=7 f1=0.923\n"
          ]
        }
      ],
      "source": [
        "# предполагая отсутствие false_positive:\n",
        "TRUE = [4, 4, 5, 6, 5, 6, 3, 4, 5, 7]  # людей на фотографии\n",
        "PRED = [3, 4, 3, 6, 5, 5, 3, 3, 4, 6]  # рамок 'person' на фотографии\n",
        "\n",
        "true_positive = sum(PRED)\n",
        "false_negative = sum(TRUE) - sum(PRED)\n",
        "recall = sum(PRED) / sum(TRUE)\n",
        "precision = 1\n",
        "f1 = (2 * precision * recall) / (precision + recall)\n",
        "print(f'{true_positive=} {false_negative=} {f1=:.3f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6",
      "language": "python",
      "name": "python36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
