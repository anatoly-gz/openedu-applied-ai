{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KgIgjT1mt9Tn"
      },
      "source": [
        "# Автоматическая обработка текстов\n",
        "\n",
        "По ссылке находится произведение русской классики. Ваша задача -- применить RNNMorph, для анализа произведения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5Fr5swwYfz5",
        "outputId": "0143c87c-e27f-43e3-f264-b5b065aad576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rnnmorph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for russian-tagsets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!pip -q install bs4 nltk rnnmorph\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "64uxt-07IEec"
      },
      "outputs": [],
      "source": [
        "DATA_URL = \"http://az.lib.ru/g/gogolx_n_w/text_0050.shtml\"\n",
        "TOP_BATCH_SIZE = 150\n",
        "MIN_COUNT_THRESHOLD = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uW0fw_h-Pft",
        "outputId": "f9dd31d1-aa49-40d1-8ed9-cfd73695cf0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 12s 707ms/step\n",
            "Количество предложений:  934\n",
            "Количество токенов, состоящих только из букв: 11732\n",
            "Доля слов, не входящих в стоп-лист, среди 150 самых частотных: 0.5733333333333334\n",
            "Количество токенов, встречающихся в тексте строго больше 10 раз:  161\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from rnnmorph.predictor import RNNMorphPredictor\n",
        "\n",
        "\n",
        "with urllib.request.urlopen(DATA_URL) as response:\n",
        "  raw_html = response.read().decode(response.headers.get_content_charset())\n",
        "soup = BeautifulSoup(raw_html, features=\"html.parser\")\n",
        "for tag in soup([\"script\", \"style\"]):\n",
        "  tag.extract()\n",
        "text_data = soup.get_text()\n",
        "\n",
        "tokenized = [word_tokenize(sentence) for sentence in sent_tokenize(text_data)]\n",
        "predictor = RNNMorphPredictor(language=\"ru\")\n",
        "normalized = [[token.normal_form for token in sentence if token.word.isalpha()] \n",
        "              for sentence in predictor.predict_sentences(tokenized)]\n",
        "tokens = [token for sentence in normalized for token in sentence]\n",
        "print('Количество предложений: ', len(normalized))\n",
        "print('Количество токенов, состоящих только из букв:', len(tokens))\n",
        "\n",
        "tokens_count = nltk.FreqDist(tokens)\n",
        "stopwords = set(nltk.corpus.stopwords.words(\"russian\"))\n",
        "print(f'Доля слов, не входящих в стоп-лист, среди {TOP_BATCH_SIZE} самых частотных:', \n",
        "      sum(token not in stopwords for token, _ in tokens_count.most_common(TOP_BATCH_SIZE)) / TOP_BATCH_SIZE)\n",
        "print(f'Количество токенов, встречающихся в тексте строго больше {MIN_COUNT_THRESHOLD} раз: ',\n",
        "      sum(count > 10 for token, count in tokens_count.items()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
